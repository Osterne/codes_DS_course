# Importando as bibliotecas necessárias
import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.utils import to_categorical

# Carregando o conjunto de dados Iris
iris = load_iris()
X = iris.data  # Atributos (features)
y = iris.target  # Rótulos (target)

# One-hot encoding para as classes
y_encoded = to_categorical(y, num_classes=3)

# Dividindo os dados em conjunto de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)

# Criando o modelo de Rede Neural (MLP - Multi-Layer Perceptron)
model = Sequential()

# Adicionando a camada de entrada (input layer) com 4 neurônios (para as 4 features)
model.add(Dense(units=8, input_dim=4, activation='relu'))  # Primeira camada oculta (relu)
model.add(Dense(units=8, activation='relu'))  # Segunda camada oculta (relu)

# Camada de saída com 3 neurônios (para as 3 classes de flores) e função de ativação softmax
model.add(Dense(units=3, activation='softmax'))

# Compilando o modelo
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Treinando o modelo
history = model.fit(X_train, y_train, epochs=100, batch_size=10, validation_split=0.2, verbose=1)

# Avaliando o modelo com o conjunto de teste
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)  # Convertendo as probabilidades para classes

# Convertendo os rótulos de teste para suas classes originais
y_test_classes = np.argmax(y_test, axis=1)

# Avaliando a acurácia
accuracy = accuracy_score(y_test_classes, y_pred_classes)
print(f'Acurácia do modelo: {accuracy:.4f}')

# Exibindo a matriz de confusão
cm = confusion_matrix(y_test_classes, y_pred_classes)
print('\nMatriz de Confusão:')
print(cm)

# Visualizando a matriz de confusão com o seaborn
plt.figure(figsize=(6,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iris.target_names, yticklabels=iris.target_names)
plt.title('Matriz de Confusão')
plt.xlabel('Previsões')
plt.ylabel('Valores Reais')
plt.show()

# Exibindo o relatório de classificação (precision, recall, f1-score)
print('\nRelatório de Classificação:')
print(classification_report(y_test_classes, y_pred_classes, target_names=iris.target_names))

# Plotando a acurácia e a perda durante o treinamento
plt.figure(figsize=(12, 6))

# Gráfico da acurácia
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Acurácia Treinamento')
plt.plot(history.history['val_accuracy'], label='Acurácia Validação')
plt.title('Acurácia durante o Treinamento')
plt.xlabel('Épocas')
plt.ylabel('Acurácia')
plt.legend()

# Gráfico da perda (loss)
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Perda Treinamento')
plt.plot(history.history['val_loss'], label='Perda Validação')
plt.title('Perda durante o Treinamento')
plt.xlabel('Épocas')
plt.ylabel('Perda')
plt.legend()

plt.tight_layout()
plt.show()
