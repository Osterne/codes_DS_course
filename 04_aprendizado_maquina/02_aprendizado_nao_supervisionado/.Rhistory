# 1. Carregar as bibliotecas necessárias
library(ggplot2)        # Para visualizações gráficas
library(cluster)         # Para visualização de agrupamentos
library(factoextra)      # Para avaliação de agrupamentos (função fviz_cluster)
# 1. Carregar as bibliotecas necessárias
library(ggplot2)        # Para visualizações gráficas
library(cluster)         # Para visualização de agrupamentos
library(factoextra)      # Para avaliação de agrupamentos (função fviz_cluster)
data(iris)
# Visualizar as primeiras linhas dos dados
head(iris)
# 3. Pré-processamento dos dados
# Usaremos apenas as variáveis numéricas para o clustering
iris_data <- iris[, 1:4]  # Selecionando apenas as colunas numéricas
iris_data
# 4. Aplicar o algoritmo K-means
set.seed(123)
# Aplicando o K-means com 3 clusters, já que sabemos que o conjunto de dados Iris tem 3 espécies
kmeans_model <- kmeans(iris_data, centers = 3, nstart = 25)
# Visualizando o resumo do modelo K-means
print(kmeans_model)
# 5. Avaliar o desempenho do agrupamento
# Verificando a tabela de clusters atribuídos
table(kmeans_model$cluster, iris$Species)
# 6. Visualizar os resultados do clustering
# Visualizando o agrupamento em um gráfico 2D (Sepal.Length vs Sepal.Width)
fviz_cluster(kmeans_model, data = iris_data,
ellipse.type = "convex", # Exibir elipses convexas
ggtheme = theme_minimal()) # Tema minimalista
# Visualizando os agrupamentos no gráfico com o número de clusters
# Usando a primeira e segunda variável para visualização
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = factor(kmeans_model$cluster))) +
geom_point() +
labs(title = "K-Means Clustering", color = "Cluster") +
theme_minimal()
# 6. Visualizar os resultados do clustering
# Visualizando o agrupamento em um gráfico 2D (Sepal.Length vs Sepal.Width)
fviz_cluster(kmeans_model, data = iris_data,
ellipse.type = "convex", # Exibir elipses convexas
ggtheme = theme_minimal()) # Tema minimalista
# 7. Avaliação adicional do modelo
# Podemos calcular a soma dos quadrados intra-cluster (total within-cluster sum of squares)
# Esse valor pode ser usado para avaliar a qualidade do agrupamento
print(paste("Total Within-Cluster Sum of Squares: ", kmeans_model$tot.withinss))
# 1. Carregar as bibliotecas necessárias
library(ggplot2)        # Para visualizações gráficas
library(cluster)         # Para visualização de agrupamentos
library(factoextra)      # Para avaliação de agrupamentos (função fviz_cluster)
# 2. Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já está carregado no R
head(iris)
iris_data <- iris[, 1:4]
iris_data
iris_data
# 4. Aplicar o algoritmo K-means
set.seed(123)  # Para reprodutibilidade
# Aplicando o K-means com 3 clusters, já que sabemos que o conjunto de dados Iris tem 3 espécies
kmeans_model <- kmeans(iris_data, centers = 3, nstart = 25)
print(kmeans_model)
kmeans_model$cluster
iris$Species
# 5. Avaliar o desempenho do agrupamento
# Verificando a tabela de clusters atribuídos
table(kmeans_model$cluster, iris$Species)
# 6. Visualizar os resultados do clustering
# Visualizando o agrupamento em um gráfico 2D (Sepal.Length vs Sepal.Width)
fviz_cluster(kmeans_model, data = iris_data,
ellipse.type = "convex", # Exibir elipses convexas
ggtheme = theme_minimal()) # Tema minimalista
# Usando a primeira e segunda variável para visualização
ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, color = factor(kmeans_model$cluster))) +
geom_point() +
labs(title = "K-Means Clustering", color = "Cluster") +
theme_minimal()
# Carregar as bibliotecas necessárias
library(ggplot2)        # Para visualizações gráficas
library(cluster)         # Para visualização dos agrupamentos
library(factoextra)      # Para avaliar os agrupamentos e visualizações de cluster
library(dendextend)      # Para manipulação e visualização de dendrogramas
# Carregar as bibliotecas necessárias
library(ggplot2)        # Para visualizações gráficas
library(cluster)         # Para visualização dos agrupamentos
library(factoextra)      # Para avaliar os agrupamentos e visualizações de cluster
library(dendextend)      # Para manipulação e visualização de dendrogramas
# Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já está carregado no R
# Visualizar as primeiras linhas dos dados
head(iris)
# Pré-processamento dos dados
# Usaremos apenas as variáveis numéricas para o clustering
iris_data <- iris[, 1:4]  # Selecionando apenas as colunas numéricas
# Usaremos a distância euclidiana para calcular as distâncias entre as amostras
dist_matrix <- dist(iris_data, method = "euclidean")
# 5. Aplicar o algoritmo de Clusterização Hierárquica
# Usaremos o método de ligação (linkage) "complete", mas existem outros como "single", "average", etc.
hclust_model <- hclust(dist_matrix, method = "complete")
# 6. Visualizar o dendrograma
# O dendrograma nos mostra como os clusters são formados e o nível de aglomeração
plot(hclust_model, main = "Dendrograma da Clusterização Hierárquica",
xlab = "", ylab = "Distância Euclidiana", sub = "", cex = 0.9)
# 7. Cortar o dendrograma para definir os clusters
# Vamos cortar o dendrograma em 3 clusters
clusters <- cutree(hclust_model, k = 3)
# 8. Avaliar o desempenho do agrupamento
# Comparar os clusters formados com as classes reais (Species)
table(clusters, iris$Species)
# 9. Visualizar os resultados do clustering
# Visualizar os clusters em um gráfico 2D usando a primeira e a segunda variável (Sepal.Length e Sepal.Width)
iris_clustered <- data.frame(iris, Cluster = as.factor(clusters))
ggplot(iris_clustered, aes(x = Sepal.Length, y = Sepal.Width, color = Cluster)) +
geom_point() +
labs(title = "Clusterização Hierárquica", color = "Cluster") +
theme_minimal()
# 10. Visualizar os clusters em um gráfico 3D (opcional)
# Usando a biblioteca 'scatterplot3d' para visualização 3D (caso queira uma visualização mais elaborada)
if (requireNamespace("scatterplot3d", quietly = TRUE)) {
library(scatterplot3d)
scatterplot3d(iris_clustered$Sepal.Length, iris_clustered$Sepal.Width, iris_clustered$Petal.Length,
color = iris_clustered$Cluster, pch = 16,
main = "Visualização 3D dos Clusters")
}
# Carregar as bibliotecas necessárias
library(ggplot2)        # Para visualizações gráficas
library(cluster)         # Para visualização dos agrupamentos
library(factoextra)      # Para avaliar os agrupamentos e visualizações de cluster
library(dendextend)      # Para manipulação e visualização de dendrogramas
# Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já está carregado no R
# Visualizar as primeiras linhas dos dados
head(iris)
# Pré-processamento dos dados
# Usaremos apenas as variáveis numéricas para o clustering
iris_data <- iris[, 1:4]  # Selecionando apenas as colunas numéricas
# Usaremos a distância euclidiana para calcular as distâncias entre as amostras
dist_matrix <- dist(iris_data, method = "euclidean")
dist_matrix
# 5. Aplicar o algoritmo de Clusterização Hierárquica
# Usaremos o método de ligação (linkage) "complete", mas existem outros como "single", "average", etc.
hclust_model <- hclust(dist_matrix, method = "complete")
# 6. Visualizar o dendrograma
# O dendrograma nos mostra como os clusters são formados e o nível de aglomeração
plot(hclust_model, main = "Dendrograma da Clusterização Hierárquica",
xlab = "", ylab = "Distância Euclidiana", sub = "", cex = 0.9)
# 7. Cortar o dendrograma para definir os clusters
# Vamos cortar o dendrograma em 3 clusters
clusters <- cutree(hclust_model, k = 3)
# 7. Cortar o dendrograma para definir os clusters
# Vamos cortar o dendrograma em 3 clusters
clusters <- cutree(hclust_model, k = 3)
# 8. Avaliar o desempenho do agrupamento
# Comparar os clusters formados com as classes reais (Species)
table(clusters, iris$Species)
# 9. Visualizar os resultados do clustering
# Visualizar os clusters em um gráfico 2D usando a primeira e a segunda variável (Sepal.Length e Sepal.Width)
iris_clustered <- data.frame(iris, Cluster = as.factor(clusters))
ggplot(iris_clustered, aes(x = Sepal.Length, y = Sepal.Width, color = Cluster)) +
geom_point() +
labs(title = "Clusterização Hierárquica", color = "Cluster") +
theme_minimal()
# Carregar as bibliotecas necessárias
library(caret)  # Para divisão dos dados e métricas de avaliação
library(rpart)  # Para construir a árvore de decisão
library(rpart.plot)  # Para visualizar a árvore
# Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já vem carregado no R
# Visualizar as primeiras linhas dos dados
head(iris)
# Dividir os dados em treino e teste
set.seed(123)  # Para reprodutibilidade
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
# O modelo será treinado usando a variável 'Species' como alvo e as outras variáveis como preditoras
model <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = trainData,
method = "class")
# Visualizar a árvore de decisão
rpart.plot(model)
# Fazer previsões no conjunto de teste
predictions <- predict(model, testData, type = "class")
predictions
# Avaliar o desempenho do modelo
# Gerar a matriz de confusão
confMatrix <- confusionMatrix(predictions, testData$Species)
print(confMatrix)
# Avaliar a acurácia
accuracy <- confMatrix$overall['Accuracy']
print(paste("Acurácia do modelo:", accuracy))
# Verificar a importância das variáveis
print(model$variable.importance)
# Carregar as bibliotecas necessárias
library(caret)  # Para divisão dos dados e métricas de avaliação
library(rpart)  # Para construir a árvore de decisão
library(rpart.plot)  # Para visualizar a árvore
# Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já vem carregado no R
# Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já vem carregado no R
# Visualizar as primeiras linhas dos dados
head(iris)
# Dividir os dados em treino e teste
set.seed(123)  # Para reprodutibilidade
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
# Dividir os dados em treino e teste
set.seed(123)  # Para reprodutibilidade
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
# Treinar o modelo de árvore de decisão
# O modelo será treinado usando a variável 'Species' como alvo e as outras variáveis como preditoras
model <- rpart(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = trainData,
method = "class")
# Visualizar a árvore de decisão
rpart.plot(model)
# Fazer previsões no conjunto de teste
predictions <- predict(model, testData, type = "class")
predictions
# Avaliar o desempenho do modelo
# Gerar a matriz de confusão
confMatrix <- confusionMatrix(predictions, testData$Species)
print(confMatrix)
# Avaliar o desempenho do modelo
# Gerar a matriz de confusão
confMatrix <- confusionMatrix(predictions, testData$Species)
print(confMatrix)
# Avaliar a acurácia
accuracy <- confMatrix$overall['Accuracy']
print(paste("Acurácia do modelo:", accuracy))
# 1. Carregar as bibliotecas necessárias
library(caret)        # Para divisão dos dados e métricas de avaliação
library(randomForest) # Para construir o modelo Random Forest
# 1. Carregar as bibliotecas necessárias
library(caret)        # Para divisão dos dados e métricas de avaliação
library(randomForest) # Para construir o modelo Random Forest
# 1. Carregar as bibliotecas necessárias
library(caret)        # Para divisão dos dados e métricas de avaliação
library(randomForest) # Para construir o modelo Random Forest
# 2. Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já vem carregado no R
# Visualizar as primeiras linhas dos dados
head(iris)
# 3. Dividir os dados em treino e teste
set.seed(123)  # Para reprodutibilidade
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
# 4. Treinar o modelo Random Forest
# O modelo será treinado com a variável 'Species' como alvo e as outras variáveis como preditoras
rf_model <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = trainData,
importance = TRUE)
# 5. Visualizar o modelo
print(rf_model)
# 6. Fazer previsões no conjunto de teste
predictions <- predict(rf_model, testData)
predictions
# 5. Visualizar o modelo
print(rf_model)
# 1. Carregar as bibliotecas necessárias
library(caret)        # Para divisão dos dados e métricas de avaliação
library(randomForest) # Para construir o modelo Random Forest
# 2. Carregar o conjunto de dados Iris
data(iris)  # O conjunto de dados Iris já vem carregado no R
# Visualizar as primeiras linhas dos dados
head(iris)
# 3. Dividir os dados em treino e teste
set.seed(123)  # Para reprodutibilidade
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
rf_model <- randomForest(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data = trainData,
importance = TRUE)
# 5. Visualizar o modelo
print(rf_model)
predictions <- predict(rf_model, testData)
predictions
# 7. Avaliar o desempenho do modelo
# Gerar a matriz de confusão
confMatrix <- confusionMatrix(predictions, testData$Species)
print(confMatrix)
# 8. Avaliar a acurácia
accuracy <- confMatrix$overall['Accuracy']
print(paste("Acurácia do modelo:", accuracy))
